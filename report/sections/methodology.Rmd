# Methodology

In this section we explain the key components of our experimental design, including our sampling frame, data collection and blocking, survey design, email sending strategy, and identification of compliers, non-compliers, and attriters.

## Scraping alumni data

To obtain the official UC Berkeley School of Information (hereafter referred to as UCB I School) email addresses for all MIDS alumni, our team wrote a Python script to scrape selected pages from the UCB I School website's people directory [@noauthor_people_2021].  The script relies on the Selenium package for Python, which is an open-source tool for browser automation [@muthukadan_selenium_2021].  The script is provided for reference in Appendix B. 

Specifically, the team scraped information from all pages listing MIDS graduates, of which the website lists 1,105 as of the end of Spring 2021.  These 1,105 alumni represent the sampling frame for this experiment.  The web pages include not only the I School email address of each alumnus, but also the person's name and graduation year.^[There were two missing email addresses and one missing graduation year in the scraped data.  We identified the email addresses using the UCB I School Slack workspace and validated the missing graduation year using LinkedIn.]

## Blocking

In order to improve the precision of our estimated causal effect, we randomly assigned the 1,105 alumni into the control and two treatment groups using blocks based on graduation year (2015-2021) and gender (male, female, or unknown).  We expect blocking on graduation year to improve the precision of our estimated causal effect because it is plausible that earlier MIDS graduates might have lower survey response rates, on average, than alumni who more recently graduated from MIDS.  Similarly, we blocked on gender because studies suggest that women may be more likely to respond to surveys than men in a variety of contexts [_e.g._, @smith_does_2008].

Alumni gender designations were not available to scrape from the UCB I School website's people directory.  Therefore, we inferred each alumnus' gender based on the person's name and photograph (from the people directory or LinkedIn, if available).^[We used a binary gender designation: male or female.  Without more data, more specific gender designations were not possible.  Additionally, blocking based on more disaggregated gender designations seems unlikely to improve the precision of our causal effect estimate relative to a binary gender designation.]  Out of the 1,105 MIDS alumni, we confidently classified 789 (71.4%) as male and 299 (27.1%) as female.  We classified the remaining 17 (1.5%) alumni as "unknown" because we did not have enough information to confidently classify them as male or female.

We used the blockTools library in R to block-randomize the 1,105 alumni into the control and two treatment groups by blocking on graduation year and inferred gender [@moore_package_2016].  Figure \@ref(fig:blocks-table) shows the number of alumni assigned to each of the three groups by graduation year and gender.  Each cell in Figure \@ref(fig:blocks-table) contains three numbers, which correspond to the number of alumni assigned to each of three groups (control and two treatment) for that block.  For a given block, the same number of alumni are assigned to each group when possible.  In cases where the number of alumni in the block do not evenly divide into three groups, the number of alumni assigned to each group for a given block never differs by more than one.

```{r blocks-table, echo=FALSE, fig.align = "center", out.width = "75%", fig.cap = "Number of MIDS alumni block-randomized into each of three groups (control and two treatment) based on inferred gender and graduation year", }
knitr::include_graphics(here::here("report/images", "blocks_table.png"))
```

## Survey design and delivery architecture

Our experiment followed a progression of randomization, treatment, and outcome measurement.  Figure \@ref(fig:roxo-table) depicts the ROXO representation of our experiment, where the same ROXO design was applied to each of the 21 blocks we randomized within (denoted by the blue arrows).  In Figure \@ref(fig:roxo-table), "R" represents the block-randomization step, "X~1~" and "X~2~" represent the different treatment emails sent to the direct and philanthropic incentive groups, and "O" represents measurement of survey completions (our outcome).

```{r roxo-table, echo=FALSE, fig.align = "center", out.width = "75%", fig.cap = "ROXO construct applied to each of the 21 randomization blocks"}
knitr::include_graphics(here::here("report/images", "roxo_table.png"))
```

We delivered the control and treatment messages to the three groups of MIDS alumni using emails sent from Devesh Khandelwal's personal I-School email address(deveshkhandelwal@berkeley.edu).  (We found from testing that using a less personal email address resulted in more of our emails landing in recipients' "promotions" or "social" Gmail inboxes, rather than their "primary" inboxes.) 

The subject lines of the emails to all three groups were identical for the initial emails as well as the reminder emails (see Table \@ref(tab:email-subjects)).  Moreover, the body text of the emails were also identical for all three groups, except for the treatment text that was accentuated using bold typeface.

```{r email-subjects, echo=FALSE}
knitr::kable(
  data.frame(
    Email = c("Initial (July 2, 2021)", "July 9 and 16, 2021 Reminders",
              "July 22, 2021 Reminder", "July 23, 2021 Reminder"),
    Subject = c(
      "<<Alumnus Name>>-How Can MIDS Improve? Voice Your Opinion",
      "Reminder: <<Alumnus Name>>-How Can MIDS Improve? Voice Your Opinion",
      "ONE DAY LEFT : <<Alumnus Name>>-How Can MIDS Improve? Voice your opinion",
      "CLOSING TONIGHT: <<Alumnus Name>>-How Can MIDS Improve? Voice your opinion")),
  booktabs = TRUE,
  caption = "Email subject lines for the initial and reminder emails"
) %>% column_spec(2, width = "30em")
```

For all three groups, the treatment text indicates that alumni who complete the survey will receive a summary of the survey results.  In addition, the direct incentive group was told that alumni who complete the survey will be entered to win a \$25 Amazon gift card, and the philanthropic incentive group was told that if the overall survey response rate reaches 60%, we will donate \$250 to the Berkeley Student Food Collective.  Table \@ref(tab:email-text) shows the treatment text for all three groups, and Appendix A includes the original and reminder email templates sent to all three groups.

```{r email-text, echo=FALSE}
knitr::kable(
  data.frame(
    Group = c("Control", "Direct incentive", "Philanthropic incentive"),
    Subject = c(
      "If you complete the survey, we will send you a summary of the results.",
      "If you complete the survey, we will send you a summary of the results and you will be entered to win an Amazon gift card for $25. Ten respondents will be selected at random to receive a gift card.",
      "If you complete the survey, we will send you a summary of the results. Additionally, if we achieve a 60% response rate, we will donate $250 to the Berkeley Student Food Collective.")),
  booktabs = TRUE,
  caption = "Treatment email text for the control and two treatment groups"
) %>% column_spec(2, width = "30em")
```

Our outcome was a measurement of survey completions.  We designed a two-part survey using Qualtrics to ask about the perceived value of various aspects of the MIDS program (part one) as well as to understand the respondent's rationale for enrolling in MIDS (part two).  The first part asks the respondent to evaluate eight statements using a Likert scale.  The second part asks the respondent to answer a single multiple choice question.  We intentionally made the survey short---respondents should be able to complete the survey in 2-3 minutes---in order to maximize the likelihood of any given alumnus completing the survey.  The survey questions and a high-level results summary are provided in Appendix C.

## Sending emails and reminders

We sent initial emails to the control and two treatment groups on Friday, July 2, 2021 using Yet Another Mail Merge (YAMM).  The YAMM service took approximately 12 minutes to send the emails to the 370 (approximately) alumni in each group.  Table \@ref(tab:email-times) indicates the start times for sending emails to each group.

```{r email-times, echo=FALSE}
knitr::kable(
  data.frame(
    Group = c("Direct incentive", "Philanthropic incentive", "Control"),
    `Email Batch Start Time on July 2, 2021 (PDT)` = c(
      "9:26 am",
      "10:14 am",
      "10:40 am"),
    check.names = FALSE),
  booktabs = TRUE,
  caption = "Start times for sending initial emails to the control and two treatment groups"
)
```

In addition to the initial email that we sent to all 1,105 alumni, we sent four follow-up reminder emails.  We sent the first reminder email to all 1,105 alumni starting at 9:00 am (PDT) on July 9, 2021 (even to those who had already completed the survey).  We sent the remaining three reminder emails starting at 9:15 am (PDT) on July 16, 8:00 am (PDT) on July 22, and 9:15 am (PDT) on July 23, 2021 only to alumni who had not already completed the survey by the evening prior to sending the emails.  Figure \@ref(fig:emails-survey) shows the cumulative number of completed surveys over time, with dashed lines signifying when we sent emails.  The figure shows a clear pattern of a sharp increase in survey responses immediately after the emails are sent, with diminishing returns over time.

```{r emails-survey, echo=FALSE, fig.align = "center", out.width = "100%", fig.cap = "Cumulative survey completions over the experimental period with initial and reminder email send dates indicated by dashed vertical lines"}
knitr::include_graphics(here::here("report/images", "emails_survey_timeseries.png"))
```

## Identifying compliers, non-compliers, and attriters

The YAMM service provides a near-real time merge status indicator for each email that is sent out.  Possible status options are: sent, opened, clicked, responded, bounced, and unsubscribed.  While YAMM does not guarantee the reported status to be 100% accurate, this is the only source of data that allows us to identify non-compliers in our study [@noauthor_how_nodate].

We placed the treatment text specific to the control, direct incentive, and philanthropic incentive groups in the body of the emails, rather than in the email subject lines.  This allowed us to define a complier as someone who opened the email, given the assumption that if the person opened the email they read the treatment text.  We therefore identified compliers as those alumni for whom YAMM reported that they opened, clicked, or responded to at least one of the emails we sent them.  Conversely, non-compliers are defined as those who receive at least one of the emails, but never open any emails they receive.  As a result, these alumni are never presented with a dosage of the treatment corresponding to the group to which we assigned them.  We identified non-compliers in our study as those for whom YAMM reported that the email was sent, but not bounced (nor opened, clicked, or responded).  Finally, attriters are defined as those alumni who never receive any of the emails we sent them.  Any alumni for whom YAMM reported a bounced email from our initial email batch was deemed an attriter.  Figure \@ref(fig:flow-diagram) is a flow diagram that shows the number of alumni in each group after accounting for attriters and non-compliers.  In total, 229 MIDS alumni completed the survey, providing an overall response rate of approximately 21%.

```{r flow-diagram, echo=FALSE, fig.align = "center", out.width = "100%", fig.cap = "Flow diagram indicating the number of MIDS alumni by group after accounting for attrition and non-compliance"}
knitr::include_graphics(here::here("report/images", "flow_diagram.png"))
```

## Calculating treatment effects

For this experiment, we calculated the following treatment effects: intent-to-treat (ITT) effect, complier-average causal effect (CACE), and heterogeneous treatment effects (HTEs) using gender and graduation year subgroups.  When calculating these treatment effects, attriters were omitted from the analysis.  We omitted attriters for two reasons: 1) We do not have a measured outcome for these alumni, and 2) Omitting attriters should not bias our estimated treatment effects because the group assignment has no influence on who attrits, which is determined by whether or not the person's email account is active.

The ITT effect calculation provides an estimated treatment effect based only on the group assignment.  Because this calculation requires no discerning between compliers and non-compliers, the ITT effect is our primary result from this experiment.  The CACE, in contrast, does require knowledge of the number of compliers and non-compliers in each group.  Due to the aforementioned issues with YAMM, obtaining these estimates required us to make assumptions about who actually opened at least one of the emails they received.  As a result, we do not have as much trust in our CACE estimates as we do for our ITT effect estimates.  Finally, we analyzed HTEs for gender and graduation year subgroups based only on group assignment.  This allowed us to avoid making compliance assumptions, and it means that the estimates we obtained should be interpreted as heterogeneous ITT effects.

