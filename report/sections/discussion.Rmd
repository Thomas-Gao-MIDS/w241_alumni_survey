# Discussion

In this section we'll discuss the overall data aggregation and our approach to calculate the `treatment-effect`.

## Data flow and aggregation
As highlighted in the previous section ,our data comes from 3 main sources:

* Alumni Scrape - main data source that consists of alumni details from web scraping
* YAMM Mail Merge - populated from the alumni scrape with personal links to surveys and body of the `treatment`
* Qualtrics  - contains the information on survey respondents

The figure below represents the high-level data flow and aggregation of our data sources to arrive at our final data source for further analysis.


```{r Data flow-diagram, echo=FALSE, fig.align = "center", out.width = "100%", fig.cap = "Data Flow"}
knitr::include_graphics(here::here("report/images", "Data_flow.PNG"))
```

We performed a left join on Alumni Scrape with YAMM and Qualtrics data to ensure that each subject is identified in one of the categories-`compliers, non-compliers, and attriters`. Please refer to the previous section on the definition of each and refer to appendix C for the script.


## Checks and balances 
Before we proceeded with our analysis of the results we ensured that our covariates are balanced. This was done to validate randomization 


```{r balance check, echo=FALSE, fig.align = "center", out.width = "100%", fig.cap = "CoVariate Balance Check"}
knitr::include_graphics(here::here("report/images", "Covariate_balance_check.PNG"))
```

## Non-Compliance

As with any survey we also ran into the issues of non-compliance. We believe that our survey is only impacted by *one-sided non-compliance* where people do not respond to assigned dosage of treatment(Direct, Philanthropic and Control). This is due to the fact that we generate personal links for alumni and refrained from using  generic survey link across groups.
Our mail-merge strategy(with personalized body and subject) gave an impression of a highly targeted campaign as opposed to a generic appeal to respond to a survey campaign.We assume that these approaches would *prevent any two-sided non-compliance* where people in separate groups share the survey link with one another.

As highlighted in the previous section we calculate the treatment effect in the following categories :
* Intent to Treat(ITT)
* Complier-Average Causal Effect (CACE)
* Heterogeneous Treatment Effects (HTEs)

### Calculation of ITT

The ultimate aim for a research is to determine the Average Treatment Effect (ATE) for a population,however due to practical challenges and given the issue of non-compliance it is not always possible to get an accurate measure of the ATE.Researchers often start with a measure of ITT -  effect of treatment on ASSIGNMENT on outcome (for everybody) ignoring non-compliance.

Mathematically we define ITT as:

$ ITT = E[Y_i(z = 1)] - E[Y_i(z = 0)]$

here, z denotes 'azzignment', to one of the experimental groups.

In our experiment we ran regressions to determine ITT by comparing the three groups and the response rates(ignoring the non-compliance).
The table below provides an overview of ITT along with ITT by factoring in the groups and cohort. In general, we observed that the response rates in the Direct and Philanthropic groups were low compared to the control group.


```{r ITT model, echo=FALSE, fig.align = "center", out.width = "100%", fig.cap = "ITT models"}
knitr::include_graphics(here::here("report/images", "ITT_stargazer.PNG"))
```

We also noticed that when controlled for `cohorts` and `gender` , our treatment effect marginally decreased (~1.2 % point decrease) for the control group along with an increase in corresponding standard errors. The width of confidence interval also increases thereby making it less precise.

### Calculation of CACE

Given the presence of `Non-compliers`(subjects who don't take the treatment dosage),a more realistic measure for the treatment effect would be to calculate the effect of the treatment on compliers(subjects who take at least one treatment dosage). It is this group of subjects who are most likely to respond to the treatment and hence reflects a better picture of the results.
Note - we assume that we don't have any `Defiers` in our data.

Mathematically,
$ ITT_D = E[d_i(z = 1)- d_i(z = 0)] $
$ CACE = E[Y_i(d = 1) -Y_i(d = 0)|d_i(1)=1] $

The `exclusion` restriction holds true for our experiment.This is because `attriters` have no possibility of receiving a treatment(their emails are no longer valid) and hence we can safely assume that assignment to the specific groups has no effect beyond the received treatment.Due to this we can simplify the CACE calculation as :

$ CACE = ITT/ ITT_D $


We calculated our case by first calculating the take-up rate(proportion of subjects in a group who respond to the survey) and then scaling the ITT values by the take-up rate.Please refer to figure \@ref(fig:flow-diagram) that shows the number of alumni in each group after accounting for attriters and non-compliers.

The table below provides a snapshot of CACE for the two treatment groups with the control group as the baseline.

```{r CACE, echo=FALSE, fig.align = "center", out.width = "100%", fig.cap = "CACE models"}
knitr::include_graphics(here::here("report/images", "CACE_Stargazer.PNG"))
```

We again observe that the response rates in the treatment groups were lower than the response rates in the control.However, there are a few subtle differences that should be noted(as a result of *one-sided non-compliance*). As compared to the `Control`group.
* Subjects in `Direct` group are now ~`10 %` less likely to respond, compared to `6%`(ignoring non-compliance).
* Subjects in `Philanthropic` group are now ~`4.4 %` less likely , compared to `6%` (ignoring non-compliance).

We believe that the results in the table above for CACE, measures the treatment better, compared to ITT. The survey completion rate for the `Control` group is ~ `26%`, compared to the overall average of `21%.` These results are significant at a level of one percent.The 95% confidence interval, i.e the true survey response rate for this group could be anywhere between `26%` to `27%`.

The `Direct` incentive group on the other hand is significant at `10%` level , hence the true response rate for this group could be anywhere between `0%` to `27.5%`.We can follow a similar approach to measure the `CACE` for the `Philanthropic` group. The coefficient is not statistically significant. The response rates for people in this group can vary from `10%` to `33.7%`.

Note - It is worth nothing that both the `Direct` and the `Philanthropic` groups are not significant at 5%.For the `Direct` group we observe significance at a `10%`level but the estimates for the `Philanthropic`group is not significant at all, given its large standard errors.









