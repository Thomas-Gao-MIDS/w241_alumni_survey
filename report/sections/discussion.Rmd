# Results and Discussion

In this section we will discuss the following:

* Overall data aggregation
* Covariate balance check to validate randomization
* Calculation of the treatment-effect (ITT, HTE, CACE)

```{r load_data,echo=FALSE}
# The script below contains the code to aggregate the data:
# list of people

dt_roster <- read_csv('../../data/alumni_scrape.csv', col_types=cols()) %>%
  select(Email = email, Gender = gender, Year_Graduation = year_graduation, 
         Block = blocking_genderyear_assignments) %>% 
  mutate(Block = ifelse(
    Block == 1, "Direct", ifelse(
      Block == 2, "Philanthropic", "Control")))

# attrition, bounced, round 1 post-send merged status
r1_g1_bounce <- read_csv('../../data/round1_0702_group1_0702_0941.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) %>%
  filter(MStatus == 'BOUNCED')
r1_g2_bounce <- read_csv('../../data/round1_0702_group2_0702_1028.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) %>%
  filter(MStatus == 'BOUNCED')
r1_g3_bounce <- read_csv('../../data/round1_0702_group3_0702_1055.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) %>%
  filter(MStatus == 'BOUNCED')

# final status, sent, opened
r1_g1_status <- read_csv('../../data/round1_0702_group1_0708_1033.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) 
r1_g2_status <- read_csv('../../data/round1_0702_group2_0708_1220.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) 
r1_g3_status <- read_csv('../../data/round1_0702_group3_0708_1122.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) 
r2_status <- read_csv('../../data/round2_0709_all_0716_1117.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) 
r3_status <- read_csv('../../data/round3_0716_all_0722_1046.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) 
r4_status <- read_csv('../../data/round4_0722_all_0723_1131.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) 
r5_status <- read_csv('../../data/round5_0723_all_0724_1219.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) 

# outcome, Qualtrics completion
dt_qualtrics <- read_csv('../../data/Qualtrics_downloaded_20210726.csv', col_types=cols()) %>%
  select(Email = RecipientEmail, Duration = `Duration (in seconds)`,
         Long = LocationLongitude, Lat = LocationLatitude) %>%
  slice(3:n()) %>%
  mutate(Duration = as.numeric(Duration),
         Long = as.numeric(Long),
         Lat = as.numeric(Lat))

# emails to exclude
ex_emails <- c('deveshkhandelwal@berkeley.edu', 'rahosbach@berkeley.edu',
               'tgao2020@berkeley.edu', 'tgao2020@berkely.edu',
               'mirza2020@berkeley.edu')
```


```{r combine_data,echo= FALSE}

dt_agg <- 
  # roster does not contain us
  dt_roster %>%
  select(Email) %>%
  
  # bounce
  left_join(bind_rows(r1_g1_bounce, r1_g2_bounce, r1_g3_bounce) %>%
              add_column(bounce = 1) %>%
              select(-MStatus),
            by = 'Email') %>%
  replace(is.na(.), 0) %>%
  
  # non-compliance: email_sent status for all 5 rounds
  left_join(
    
    dt_roster %>% select(Email) %>% add_column(MStatus='EMAIL_SENT') %>%
      
      inner_join(r3_status %>% filter(MStatus == 'EMAIL_SENT') %>% select(Email), 
                 by='Email') %>%
      inner_join(r4_status %>% filter(MStatus == 'EMAIL_SENT') %>% select(Email), 
                 by='Email') %>% # 4 & 5 are the same?
      inner_join(r5_status %>% filter(MStatus == 'EMAIL_SENT') %>% select(Email), 
                 by='Email') %>%
      add_column(non_complier = 1) %>%
      select(-MStatus),
    by = 'Email') %>%
  replace(is.na(.), 0) %>%
  
  # compliers: people who opened at least 1 round
  mutate(complier = 1 - (bounce + non_complier)) %>%
  
  # completion: qualtrics records
  left_join(dt_qualtrics %>% select(Email) %>% add_column(completion=1), by = 'Email') %>%
  replace(is.na(.), 0) %>%
  
  # override some incorrect YAMM data
  # (these two lines correct rows for 4 people, all in the philanthropic group)
  # vishal, ansjory, taeil.goh, and davidhou
  mutate(non_complier = if_else(completion == 1, 0, non_complier),
         complier = if_else(completion == 1, 1, complier)) %>% 
  
  # meta data
  left_join(dt_roster, by = 'Email') %>%
  left_join(dt_qualtrics, by = 'Email') 

```

## Checks and balances 

Covariate balance check is a recommended approach to validate randomization which in turn ensures a fair "apples to apples" comparison. While one can perform a covariate balance check on different characteristics across the three groups, we focus on performing the balance check on the YAMM data to identify compliers, attriters and non-compliers. As we pointed out (and also validated) in the previous section, R blocking ensures that our data is balanced across cohorts and genders. Figure 6 shows plot the number of attriters, non-compliers and compilers, and through visual inspection, we see a similar attrition and compliance rates. 

```{r cov_balance, echo=FALSE}

dt_cb <- dt_agg %>% 
  select(Block, bounce, non_complier, complier, completion)  %>%
  data.table()

cb1 <- dt_cb[, lm(bounce~Block)]
cb2 <- dt_cb[, lm(non_complier~Block)]
cb3 <- dt_cb[, lm(complier~Block)]

```

```{r Graphical Representation , echo = FALSE, fig.cap = "Stacked bar chart showing number of attriters, compliers, and non-compliers in each group"}
options(dplyr.summarise.inform = FALSE)

dt_agg %>% 
  select(Block, bounce, non_complier, complier, completion) %>%
  gather(measure, value, -Block) %>%
  group_by(Block, measure) %>%
  summarise(value = sum(value)) %>%
  ungroup() %>%
  filter(measure != 'completion') %>%
  mutate(measure = recode_factor(measure, 
                                 bounce = "Email Bounced (Attrition)", 
                                 non_complier = 'Did Not Open (Non-Complier)',
                                 complier = "Opened Email (Complier)")) %>%
  # plotting
  ggplot(aes(x=Block, y=value, fill=measure)) +
  geom_col() +
  labs(x='Treatment Group', y='Count', title='Covariate Balance Check',
       fill='Status') +
  scale_fill_brewer(palette = 'Accent') +
  theme_bw()

options(dplyr.summarise.inform = TRUE)

```
More formally, in the table below, we perform regression analysis of attrition, non-compliance and compliance status on the group assignment variable and did not find statistically different results of treatment groups from the control group.

```{r Co-variate Balance check stargazer , echo=FALSE,comment=''}

stargazer(cb1, cb2, cb3, 
          type="text",
          
          omit.stat = c('ser', 'adj.rsq'),
          
          title = "Covariate Balance Check",
          covariate.labels = c("Group: Direct", 
                               "Group: Philanthropic",
                               "Constant"),
          dep.var.labels = c("Attrition", 'Non-Compliance', 'Compliance'))


```


## Non-Compliance

As with any survey campaign we also ran into the issues of non-compliance. We believe that our survey is only impacted by *one-sided non-compliance*, whereby those assigned to a particular treatment did not receive that treatment. (i.e. They received but did not open the email). This is because we generate personal links for each subject and refrained from using a generic survey link across groups.
Our mail-merge strategy (with personalized body and subject) also gives an impression of a highly targeted campaign as opposed to a generic appeal to respond to a survey. Our understanding is that these approaches help minimize two-sided non-compliance where people in different groups share the survey link with one another.

As highlighted in the previous section we calculate the treatment effect in the following categories:

* Intent to Treat (ITT)
* Complier-Average Causal Effect (CACE)
* Heterogeneous Treatment Effect (HTE)

### Calculation of ITT

The ultimate aim for a research is to determine the Average Treatment Effect (ATE) for a population, however due to practical challenges and given the issue of non-compliance it is not always possible to get an accurate measure of the ATE. Researchers often start with a measure of ITT - effect of treatment *assignment* on outcome (for everybody) ignoring non-compliance.

Mathematically we define ITT as:

$$ ITT = E[Y_i(z = 1)] - E[Y_i(z = 0)]$$

where z denotes *assignment* to one of the experimental groups.

After removing the attriters, we perform two regressions to estimate the ITT effect. First, the survey completion variable is regressed on the group assignment variable with the control group as base case. We also perform a second regression by adding gender and cohort covariates to the first regression as controls. 


```{r ITT Calculation , echo=FALSE}
#The code chunk below calculates the regression .
d <- data.table(dt_agg)

# Generate models
m1 <- d[bounce == 0 , lm(completion ~ Block)]
m2 <- d[bounce == 0 , lm(completion ~ Block + Gender + factor(Year_Graduation))]

# Calculate robust SEs for both models
rse1 <- sqrt(diag(vcovHC(m1)))
rse2 <- sqrt(diag(vcovHC(m2)))

```
The table below summarizes the regression results.

```{r stargazer ITT,comment='',echo=FALSE}
stargazer(m1, m2, 
          type="text",
          se = list(rse1, rse2),
          
          #no.space = T, 
          omit.stat = c('ser', 'f', 'adj.rsq'),
          omit = c('Gender', 'Year_Graduation'),
          add.lines = list(c('Gender Fixed Effects?', 'No', 'Yes'),
                           c('Cohort Fixed Effects?', 'No', 'Yes')),
          
          title = "ITT Estimate with Attriters Removed",
          covariate.labels = c("Group: Direct", "Group: Philanthropic",
                               #"Gender: Male", "Gender: Unknown",
                               #"Cohort: 2016", "Cohort: 2017",
                               #"Cohort: 2018", "Cohort: 2019",
                               #"Cohort: 2020", "Cohort: 2021",
                               "Constant"),
          dep.var.labels = "Survey Completion")

```
  

Key Findings on ITT(for cohort and gender fixed effects):

* Direct incentive reduced the likelihood to complete the survey by 6.2% (compared to control) with a 95% confidence interval of [-13%, -3%]).
* Philanthropic incentive reduced the likelihood of completion by 2.6% (compared to control) with a 95% confidence interval of [-9%, -.8%]).
* Neither effects are statistically significant at 95% confidence level, although the direct incentive effect is significant at 90% confidence level.
* The coefficients and standard errors are approximately the same for the two models, which provides validation that black randomization worked as we expected. We see a lower standard error on the constant term(when controlled for cohort and gender) because our group size reduces and as a result standard error increase a bit.

### Calculation of CACE

Given the presence of Non-compliers (subjects who don't take the treatment dosage), a more realistic measure for the treatment effect would be to calculate the effect of the treatment on compliers (subjects who take at least one treatment dosage). It is this group of subjects who are most likely to respond to the treatment and hence reflects a better picture of the results.

Mathematically,
$$ ITT_D = E[d_i(z = 1)- d_i(z = 0)] $$

$$ CACE = E[Y_i(d = 1) -Y_i(d = 0)|d_i(1)=1] $$

Based on the assumptions mentioned in the methodology, we can define CACE as follows.

$$ CACE = ITT/ ITT_D $$


We calculate the CACE by first calculating the take-up rate (proportion of subjects in a group who respond to the survey) and then scaling the ITT values by the take-up rate. Please refer to figure \@ref(fig:flow-diagram) that shows the number of alumni in each group after accounting for attriters and non-compliers.
We believe that this ratio of ITT and ITT_d is an unbiased estimate of CACE because of the validaity of assumptions(monotonicity, exclusion restriction and randomization) stated in the previous section.

```{r cace, comment='', echo=FALSE}
# The chunk below shows the r code to calculate the CACE
# Calculate the CACE for each treatment group manually
ittd_direct <- 
  d[bounce == 0 & Block == "Direct" & complier == 1, .N] /
  d[bounce == 0 & Block == "Direct" , .N]
ittd_philanthropic <- 
  d[bounce == 0 & Block == "Philanthropic" & complier == 1, .N] /
  d[bounce == 0 & Block == "Philanthropic" , .N]

cace_direct <- m2$coefficients['BlockDirect'] / ittd_direct
cace_philanthropic <- m2$coefficients['BlockPhilanthropic'] / ittd_philanthropic

cace_table <- 
  data.table(Treatment = c('Direct', 'Philanthropic'),
             ITT = m2$coefficients[c('BlockDirect', 'BlockPhilanthropic')],
             ITTd = c(ittd_direct, ittd_philanthropic),
             CACE = c(cace_direct, cace_philanthropic))


# Generate IV regression models
d[ , treated := complier * (Block != "Control")]
ivmod_direct <- d[bounce == 0 & Block != "Philanthropic",
                  ivreg(completion ~ treated | Block)]
ivmod_philanthropic <- d[bounce == 0 & Block != "Direct",
                         ivreg(completion ~ treated | Block)]

# Calculate robust SEs for the IV regression models
rseiv_direct <- sqrt(diag(vcovHC(ivmod_direct)))
rseiv_philanthropic <- sqrt(diag(vcovHC(ivmod_philanthropic)))

stargazer(cace_table, type = 'text', 
          summary = F, rownames = F,
          title = 'CACE = ITT / ITTd')

```
  
We also validate our CACE by making use of Instrumental variables. We perform two stage least squared (2SLS) regressions using the ivreg function in the AER R package. To estimate the CACE for the direct group , we exclude attriters and subjects receiving philanthropic treatments. We then perform the 2SLS regression with survey completion status as outcome variable, whether people complied and received direct incentive as dosage, and treatment assignment as instrument. This is equivalent to regressing dosage on treatment assignment in the first step, and regressing outcome variable on the fitted dosage values in the second step. We do the same for philanthropic incentives as well.

```{r Stargazer CACE, comment='',echo= FALSE}

stargazer(ivmod_direct, ivmod_philanthropic, 
          type="text",
          se = list(rseiv_direct, rseiv_philanthropic),
          
          omit.stat = c('rsq', 'adj.rsq', 'ser'),
          
          title = "CACE (IVreg) Estimate with Attriters Removed",
          dep.var.labels = "Survey Completion",
          covariate.labels = 'Treated',
          column.labels = c("Direct", "Philanthropic"))

```
&nbsp;
  
Key Findings on CACE:

Because CACE estimates account for non-compliance when estimate the effects, we believe that they are better representations of the treatment effects than ITT.

* Response rates in the treatment groups were lower than the response rates in the control.However, there are a few subtle differences that should be noted(as a result of *one-sided non-compliance*). As compared to the control group.
  -  Subjects in direct group are now ~10 % less likely to respond with a 95% confidence interval of [-21%, -4.4%]), compared to 6% (ITT estimate).
  -  Subjects in philanthropic group are now ~4 % less likely to respond with a 95% confidence interval of [-16.2%, 1.5%]), compared to 2.6% (ignoring non-compliance).
  
* The survey completion rate for the control group is ~ 26% on average range with a 95% confidence interval of [21.3%,31.3%]), compared to the overall survey response average of 21%. These results are significant at a level of one percent.The 95% confidence interval, i.e the true survey response rate for the control group could be anywhere between 21% to 29%. The point estimate of the treatment effect for this group is not statistically significant. 

Note - It is worth noting that both the direct and the philanthropic groups are not significant at 5% level. For the direct group we observe significance at a 10% level but the estimates for the philanthropic group is not significant, given its large standard errors.


### Heterogeneous Treatment Effects (HTEs)

We also calculated to see whether the response rates were different by cohorts/gender. This could help us to determine subgroups that are more likely to respond similar treatments. 

Here, we analyze the results of how treatment effects vary by gender.

```{r hte, echo = FALSE}

# HTE for different gender
m3 <- d[bounce == 0 & Gender != 'U', lm(completion ~ Gender * Block)]
rse3 <- sqrt(diag(vcovHC(m3)))

# HTE for different gender, controlling for cohort effect
m4 <- d[bounce == 0 & Gender != 'U', lm(completion ~ Gender * Block + factor(Year_Graduation))]
rse4<- sqrt(diag(vcovHC(m4)))
```


```{r hte_2 , echo= FALSE}

# HTE between grad year and treatment
m5 <- d[bounce == 0 & Gender != 'U', lm(completion ~ factor(Year_Graduation) * Block)]
rse5 <- sqrt(diag(vcovHC(m5)))


m6 <- d[bounce == 0 & Gender != 'U', lm(completion ~ factor(Year_Graduation) * Block + Gender)]
rse6 <- sqrt(diag(vcovHC(m6)))

```

The table below calculates the HTEs for Gender and Graduation-Year.

```{r stargazer gender , comment='', echo = FALSE}

stargazer(m3, m4,
          type="text",
          se = list(rse3, rse4),
          
          no.space = T,
          omit.stat = c('ser', 'f', 'adj.rsq'),
          omit = c('Year_Graduation'),
          add.lines = list(c('Cohort Fixed Effects?', 'No', 'Yes'),
                           c('Excl. Gender Unknown?', 'Yes', 'Yes')),

          title = "Heterogeneous Treatment Effect",
          covariate.labels = c('Male',
                               'Group: Direct', 'Group: Philanthropic',
                               'Male + Direct', 'Male + Philanthropic',
                               "Constant"),
          dep.var.labels = "Survey Completion")

```
&nbsp;
  
We run a regression model to get HTEs and based on the coefficients obtained interpret one of these regression(labeled as 'cohort Fixed Effects ? No ') as below:

$$ Y = .216 + .072*gender - (.025)*direct + (.023)* philanthropic - (.056)*(direct*gender) - (.074)*(philanthropic*gender) + \epsilon$$
where :
* gender : is a dummy variable(female = 1 , male = 0)
* direct : is a dummy variable(direct = 1 indicates that the subject belongs to the direct incentive group)
* philanthropic : is a dummy variable (philanthropic = 1 indicates that the subject belongs to the philanthropic incentive group)
* $\epsilon$ : is the error term.

We interpret the regression results as follows(this is labeled as 'cohort Fixed Effects ? No ' in the table above):

* Response rates for females in control group is significant at 1% level, and on average their response rate is ~21.6% .
* Response rates for *men* in controlgroup is **not** significant and relative to females in the control group their response rate is [-3.6,12.6] with a 95% confidence interval.
* The co-efficient of interaction term is **not** significant but we can calculate a relative response rates (**relative to females in the control group**) .
- The response rates for females in the direct group can range from [-9.7%,14.7%] with a 95% confidence interval.
- Response rates for males in the direct group is .9% lower. Their true response rate can range from [-39.5%,37.7%] with a 95% confidence interval.

With a similar analysis we can compare the response rates between males and females in the philanthropic group.





We also performed a heterogeneous treatment analysis of gender and cohort groups and evaluated whether any of the interaction models that we define are better at explaining the variance of the response rates. 

```{r HTE by gender and cohort, echo=FALSE}
# HTE between grad year and treatment

m5 <- d[bounce == 0 & Gender != 'U' & complier == 1, lm(completion ~ factor(Year_Graduation) * Block)]
rse5 <- sqrt(diag(vcovHC(m5)))


m6 <- d[bounce == 0 & Gender != 'U' & complier == 1, lm(completion ~ factor(Year_Graduation) * Block + Gender)]
rse6 <- sqrt(diag(vcovHC(m6)))


```
The anova analyzes this variance and evaluates the null hypothesis of a significant difference between variance of response rates between the two categories of interaction models that we have defined. The values below calculates the model for HTEs across these groups.



```{r hte_f_tests, echo=FALSE, comment=''}

# F-test on gender
anova_gender<- anova(
  d[bounce == 0 & Gender != 'U' & complier == 1, lm(completion ~ Gender + Block)],
  d[bounce == 0 & Gender != 'U' & complier == 1, lm(completion ~ Gender * Block)],
  test = "F"
)

# F-test on graduation year
anova_gender_coh<- anova(
  m5 <- d[bounce == 0 & Gender != 'U' & complier == 1, lm(completion ~ factor(Year_Graduation) + Block)],
  m5 <- d[bounce == 0 & Gender != 'U' & complier == 1, lm(completion ~ factor(Year_Graduation) * Block)],
  test = "F"
)

anova_gender
anova_gender_coh
```
Findings of anova test:

- The p-value of the difference between our base model(one that doesn't include interaction) and the interaction model of Gender is `r round(anova_gender$Pr[2], 2)`, indicating that it is insignificant.
- The p-value of the difference between our non-interaction model(one that doesn't interact with year and block) and the interaction model(year and block interaction) is `r round(anova_gender_coh$Pr[2], 2)`, indicating that it is insignificant as well.


Please refer to the appendix section for a table that describes the interaction effects between treatment and cohort.

## Discussion

**For both the CACE and the ITT we noticed that the response rate was lower than what we had for the control group. This is contrary to the general belief that incentives motivate people to respond to surveys(as indicated in the introduction section). This could be due to a number of reasons, some of which are listed below:

* MIDS is a graduate degree program with a vast majority of people working full-time. We speculate that \$25 might not be right amount of incentive to people to draw their attention.
* We also suspect that the longer text in the body of the emails to the direct and the Philanthropic group might have contributed to this behavior. This is due to the fact that more and more people access their emails on a hand-held device and the attention span is inversely proportional to the length of the text.
* When analyzing HTEs we noticed that cohort of 2015 had an unusually higher response rates as compared to other cohorts.

This could be due to smaller cohort size of 40 and a tight-knit community who is invested in the program as the very first cohort.

MIDS program is run by Ischool as part of UC Berkeley. It is a part time program designed for working professionals, and our experiment was targeted exclusively at MIDS alumni and the "Call to Action" was to provide feedback to improve the overall program. We don't expect our results to generalize at the school level and hold true for other programs like MICS(a full time program also by Ischool). The results might also not generalize to other professional degree programs. This is due to the fact that the response rates is influenced by overall experience of the students. We recommend follow-up studies with a mix of students in a part-time and full-time degree program and the right degree of incentives to generalize the results.










