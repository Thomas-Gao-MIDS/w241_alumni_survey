# Results and Discussion

In this section we'll discuss the following:
* Overall data aggregation
* Covariate balance check to validate randomization
* Calculation of the `treatment-effect`(ITT, HTE, CACE)

## Data flow and aggregation
As highlighted in the previous section, our data comes from 3 main sources:

* Alumni Scrape - main data source that consists of alumni details that we obtain from web scraping.
* YAMM Mail Merge - data from the mail-merge tool that helps to track the status of an email. We need this status to determine the `attriters, compliers, non-compliers`.
* Qualtrics  - information for subjects who take the survey.

We obtain our final dataset by performing a left-join of Alumni-Scrape  with YAMM and Qualtrics data. This helps us to assign each subject into one of the categories - attriters, compliers, non-compliers.

The figure below represents the high-level data flow and aggregation of our data sources to arrive at our final data source for further analysis. Please refer to the previous section on the definition of each and refer to appendix C for the script.


```{r Data flow-diagram, echo=FALSE, fig.align = "center", out.width = "100%", fig.cap = "Data Flow"}
#setwd('home/w241_alumni_survey')

knitr::include_graphics(here::here("report/images", "Data_flow.PNG"))
```

```{r load_data,echo=FALSE}
# The script below contains the code to aggregate the data:
# list of people

dt_roster <- read_csv('../../data/alumni_scrape.csv', col_types=cols()) %>%
  select(Email = email, Gender = gender, Year_Graduation = year_graduation, 
         Block = blocking_genderyear_assignments) %>% 
  mutate(Block = ifelse(
    Block == 1, "Direct", ifelse(
      Block == 2, "Philanthropic", "Control")))

# attrition, bounced, round 1 post-send merged status
r1_g1_bounce <- read_csv('../../data/round1_0702_group1_0702_0941.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) %>%
  filter(MStatus == 'BOUNCED')
r1_g2_bounce <- read_csv('../../data/round1_0702_group2_0702_1028.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) %>%
  filter(MStatus == 'BOUNCED')
r1_g3_bounce <- read_csv('../../data/round1_0702_group3_0702_1055.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) %>%
  filter(MStatus == 'BOUNCED')

# final status, sent, opened
r1_g1_status <- read_csv('../../data/round1_0702_group1_0708_1033.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) 
r1_g2_status <- read_csv('../../data/round1_0702_group2_0708_1220.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) 
r1_g3_status <- read_csv('../../data/round1_0702_group3_0708_1122.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) 
r2_status <- read_csv('../../data/round2_0709_all_0716_1117.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) 
r3_status <- read_csv('../../data/round3_0716_all_0722_1046.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) 
r4_status <- read_csv('../../data/round4_0722_all_0723_1131.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) 
r5_status <- read_csv('../../data/round5_0723_all_0724_1219.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) 

# outcome, Qualtrics completion
dt_qualtrics <- read_csv('../../data/Qualtrics_downloaded_20210726.csv', col_types=cols()) %>%
  select(Email = RecipientEmail, Duration = `Duration (in seconds)`,
         Long = LocationLongitude, Lat = LocationLatitude) %>%
  slice(3:n()) %>%
  mutate(Duration = as.numeric(Duration),
         Long = as.numeric(Long),
         Lat = as.numeric(Lat))

# emails to exclude
ex_emails <- c('deveshkhandelwal@berkeley.edu', 'rahosbach@berkeley.edu',
               'tgao2020@berkeley.edu', 'tgao2020@berkely.edu',
               'mirza2020@berkeley.edu')
```


```{r combine_data,echo= FALSE}

dt_agg <- 
  # roster does not contain us
  dt_roster %>%
  select(Email) %>%
  
  # bounce
  left_join(bind_rows(r1_g1_bounce, r1_g2_bounce, r1_g3_bounce) %>%
              add_column(bounce = 1) %>%
              select(-MStatus),
            by = 'Email') %>%
  replace(is.na(.), 0) %>%
  
  # non-compliance: email_sent status for all 5 rounds
  left_join(
    # EMAIL_SENT not balanced.
    #bind_rows(r1_g1_status %>% filter(MStatus == 'EMAIL_SENT'),
    #          r1_g2_status %>% filter(MStatus == 'EMAIL_SENT'),
    #          r1_g3_status %>% filter(MStatus == 'EMAIL_SENT')) %>%
    #  filter(!Email %in% ex_emails) %>%
    #inner_join(r2_status %>% filter(MStatus == 'EMAIL_SENT') %>% select(Email), 
    #           by='Email') %>%
    
    # EMAIL_SENT is balanced in r3, r4 and r5
    dt_roster %>% select(Email) %>% add_column(MStatus='EMAIL_SENT') %>%
      
      inner_join(r3_status %>% filter(MStatus == 'EMAIL_SENT') %>% select(Email), 
                 by='Email') %>%
      inner_join(r4_status %>% filter(MStatus == 'EMAIL_SENT') %>% select(Email), 
                 by='Email') %>% # 4 & 5 are the same?
      inner_join(r5_status %>% filter(MStatus == 'EMAIL_SENT') %>% select(Email), 
                 by='Email') %>%
      add_column(non_complier = 1) %>%
      select(-MStatus),
    by = 'Email') %>%
  replace(is.na(.), 0) %>%
  
  # compliers: people who opened at least 1 round
  mutate(complier = 1 - (bounce + non_complier)) %>%
  
  # completion: qualtrics records
  left_join(dt_qualtrics %>% select(Email) %>% add_column(completion=1), by = 'Email') %>%
  replace(is.na(.), 0) %>%
  
  # override some incorrect YAMM data
  # (these two lines correct rows for 4 people, all in the philanthropic group)
  # vishal, ansjory, taeil.goh, and davidhou
  mutate(non_complier = if_else(completion == 1, 0, non_complier),
         complier = if_else(completion == 1, 1, complier)) %>% 
  
  # meta data
  left_join(dt_roster, by = 'Email') %>%
  left_join(dt_qualtrics, by = 'Email') 

```




## Checks and balances 


Covariate balance check is a recommended approach to validate randomization to ensure a fair "apples to apples" comparison. While one can perform a covariaate balance check on different characteristics across the three groups, we focus on performing the balance check on the YAMM data to identify compliers, attriters and non-compliers. As we pointed out and validated in the previous section, R blocking ensures that our data is balanced across cohorts and genders. Figure 6 shows plot the number of attriters, non-compliers and compilers, and through visual inspection, we see a similar attrition rate and compliance rate. 


```{r cov_balance, echo=FALSE}
# dt_agg %>% 
#   select(Block, bounce, non_complier, complier, completion) %>%
#   gather(measure, value, -Block) %>%
#   group_by(Block, measure) %>%
#   summarise(value = sum(value)) %>%
#   spread(measure, value) %>%
#   select(Block, bounce, non_complier, complier, completion) %>%
#   mutate(all = bounce + non_complier + complier, .before=2)

dt_cb <- dt_agg %>% 
  select(Block, bounce, non_complier, complier, completion)  %>%
  data.table()

cb1 <- dt_cb[, lm(bounce~Block)]
cb2 <- dt_cb[, lm(non_complier~Block)]
cb3 <- dt_cb[, lm(complier~Block)]

```

```{r Graphical Representation , echo = FALSE}
dt_agg %>% 
  select(Block, bounce, non_complier, complier, completion) %>%
  gather(measure, value, -Block) %>%
  group_by(Block, measure) %>%
  summarise(value = sum(value)) %>%
  ungroup() %>%
  filter(measure != 'completion') %>%
  mutate(measure = recode_factor(measure, 
                                 bounce = "Email Bounced (Attrition)", 
                                 non_complier = 'Did Not Open (Non-Complier)',
                                 complier = "Opened Email (Complier)")) %>%
  # plotting
  ggplot(aes(x=Block, y=value, fill=measure)) +
  geom_col() +
  labs(x='Treatment Group', y='Count', title='Covariate Balance Check',
       fill='Status') +
  scale_fill_brewer(palette = 'Accent') +
  theme_bw()

```
More formally, in the table below, we perform regression analysis of attrition, non-compliance and compliance status on the group assignment variable and did not find statistically different results of treatment groups from the control group.

```{r Co-variate Balance check stargazer , echo=FALSE,comment=''}

stargazer(cb1, cb2, cb3, 
          type="text",
          
          omit.stat = c('ser', 'adj.rsq'),
          
          title = "Covariate Balance Check",
          covariate.labels = c("Group: Direct", 
                               "Group: Philanthropic",
                               "Constant"),
          dep.var.labels = c("Attrition", 'Non-Compliance', 'Compliance'))


```


## Non-Compliance

As with any survey campaign we also ran into the issues of non-compliance. We believe that our survey is only impacted by *one-sided non-compliance*, where people do not respond to assigned dosage of treatment(Direct, Philanthropic and Control). This is because we generate personal links for each subject and refrained from using a generic survey link across groups.
Our mail-merge strategy(with personalized body and subject) also gives an impression of a highly targeted campaign as opposed to a generic appeal to respond to a survey. Our understanding is that these approaches have prevented any instances of *two-sided non-compliance* where people in different groups share the survey link with one another.

As highlighted in the previous section we calculate the treatment effect in the following categories :
* Intent to Treat(ITT)
* Complier-Average Causal Effect (CACE)
* Heterogeneous Treatment Effects (HTEs)

### Calculation of ITT

The ultimate aim for a research is to determine the Average Treatment Effect (ATE) for a population,however due to practical challenges and given the issue of non-compliance it is not always possible to get an accurate measure of the ATE.Researchers often start with a measure of ITT -  effect of treatment on ASSIGNMENT on outcome (for everybody) ignoring non-compliance.

Mathematically we define ITT as:

$$ ITT = E[Y_i(z = 1)] - E[Y_i(z = 0)]$$

here, z denotes *'azzignment'*, to one of the experimental groups.

After removing the attriters, we perform two regressions to estimate the ITT effect. First, the survey completion variable is regressed on the group assignment variable with the control group as base case. We also perform a second regression by adding Gender and Cohort covariates to the first regression as controls. 

Mathematically we can write the two regressions as below:

Regression 1: 
$$Y = \beta_0 + \beta_1Block +  \epsilon$$

Regression 2:
$$Y = \beta_0 + \beta_1Block + \beta_2gender + \beta_3gradYear + \epsilon$$
The code chunk below calculates the regression .
```{r ITT Calculation , echo=FALSE}
d <- data.table(dt_agg)

# Generate models
m1 <- d[bounce == 0 , lm(completion ~ Block)]
m2 <- d[bounce == 0 , lm(completion ~ Block + Gender + factor(Year_Graduation))]

# Calculate robust SEs for both models
rse1 <- sqrt(diag(vcovHC(m1)))
rse2 <- sqrt(diag(vcovHC(m2)))

```
The table below summarizes the regression results.

```{r stargazer ITT,comment='',echo=FALSE}
stargazer(m1, m2, 
          type="text",
          se = list(rse1, rse2),
          
          #no.space = T, 
          omit.stat = c('ser', 'f', 'adj.rsq'),
          omit = c('Gender', 'Year_Graduation'),
          add.lines = list(c('Gender Fixed Effects?', 'No', 'Yes'),
                           c('Cohort Fixed Effects?', 'No', 'Yes')),
          
          title = "ITT Estimate with Attriters Removed",
          covariate.labels = c("Group: Direct", "Group: Philanthropic",
                               #"Gender: Male", "Gender: Unknown",
                               #"Cohort: 2016", "Cohort: 2017",
                               #"Cohort: 2018", "Cohort: 2019",
                               #"Cohort: 2020", "Cohort: 2021",
                               "Constant"),
          dep.var.labels = "Survey Completion")

```

Key Findings on ITT:

* `Direct` incentive reduced the likelihood to complete the survey by 6.2%(compared to `Control`). Actual response rates can vary from `13.6%` to `26.8%`(95% Confidence Interval).
* `Philanthropic` incentive reduced the likelihood of completion by 2.6%(compared to `Control`).Actual response rates can vary from `16.9%` to `30.5%`(95% Confidence Interval).
* Neither effects are statistically significant at 95% confidence level, although the direct incentive effect is significant at 90% confidence level.
* When controlled for `cohorts` and `gender` , our treatment effect marginally decreased (~1.2 % point decrease) for the `Control` group along with an increase in corresponding standard errors. The width of confidence interval also increases thereby making it less precise.


### Calculation of CACE

Given the presence of `Non-compliers`(subjects who don't take the treatment dosage),a more realistic measure for the treatment effect would be to calculate the effect of the treatment on compliers(subjects who take at least one treatment dosage). It is this group of subjects who are most likely to respond to the treatment and hence reflects a better picture of the results.

Note - we assume that we don't have any `Defiers` in our data.

Mathematically,
$$ ITT_D = E[d_i(z = 1)- d_i(z = 0)] $$

$$ CACE = E[Y_i(d = 1) -Y_i(d = 0)|d_i(1)=1] $$

The `exclusion` restriction holds true for our experiment.This is because `attriters` have no possibility of receiving a treatment(their emails are no longer valid) and hence we can safely assume that assignment to the specific groups has no effect beyond the received treatment.Due to this we can simplify the CACE calculation as :

$$ CACE = ITT/ ITT_D $$


We calculate the CACE by first calculating the take-up rate(proportion of subjects in a group who respond to the survey) and then scaling the ITT values by the take-up rate.Please refer to figure \@ref(fig:flow-diagram) that shows the number of alumni in each group after accounting for attriters and non-compliers.


We also validated our CACE by making use of `Instrumental variables`. We performed two stage least squared (2SLS) regressions using the ivreg function in the AER R package. To estimate the CACE for the `Direct` group , we exclude attriters and subjects receiving `Philanthropic` treatments. We then perform the 2SLS regression with survey completion status as outcome variable, whether people complied and received direct incentive as dosage, and treatment assignment as instrument. This is equivalent to regressing dosage on treatment assignment in the first step, and regressing outcome variable on the fitted dosage values in the second step. We do the same for philanthropic incentives as well.

The chunk below shows the r code to calculate the CACE

```{r cace, echo=FALSE}
# Calculate the CACE for each treatment group manually
ittd_direct <- 
  d[bounce == 0 & Block == "Direct" & complier == 1, .N] /
  d[bounce == 0 & Block == "Direct" , .N]
ittd_philanthropic <- 
  d[bounce == 0 & Block == "Philanthropic" & complier == 1, .N] /
  d[bounce == 0 & Block == "Philanthropic" , .N]

cace_direct <- m2$coefficients['BlockDirect'] / ittd_direct
cace_philanthropic <- m2$coefficients['BlockPhilanthropic'] / ittd_philanthropic

cace_table <- 
  data.table(Treatment = c('Direct', 'Philanthropic'),
             ITT = m2$coefficients[c('BlockDirect', 'BlockPhilanthropic')],
             ITTd = c(ittd_direct, ittd_philanthropic),
             CACE = c(cace_direct, cace_philanthropic))


# Generate IV regression models
d[ , treated := complier * (Block != "Control")]
ivmod_direct <- d[bounce == 0 & Block != "Philanthropic",
                  ivreg(completion ~ treated | Block)]
ivmod_philanthropic <- d[bounce == 0 & Block != "Direct",
                         ivreg(completion ~ treated | Block)]

# Calculate robust SEs for the IV regression models
rseiv_direct <- sqrt(diag(vcovHC(ivmod_direct)))
rseiv_philanthropic <- sqrt(diag(vcovHC(ivmod_philanthropic)))

```

The table below shows the summary of the regression results.
```{r Stargazer CACE, comment='',echo= FALSE}
stargazer(cace_table, type = 'text', 
          summary = F, rownames = F,
          title = 'CACE = ITT / ITTd')


stargazer(ivmod_direct, ivmod_philanthropic, 
          type="text",
          se = list(rseiv_direct, rseiv_philanthropic),
          
          omit.stat = c('rsq', 'adj.rsq', 'ser'),
          
          title = "CACE (IVreg) Estimate with Attriters Removed",
          dep.var.labels = "Survey Completion",
          covariate.labels = 'Treated',
          column.labels = c("Direct", "Philanthropic"))


```

Key Findings on CACE:
We believe that the results in the table above for CACE, measures the treatment better, compared to ITT.

* Response rates in the treatment groups were lower than the response rates in the control.However, there are a few subtle differences that should be noted(as a result of *one-sided non-compliance*). As compared to the `Control`group.
  -  Subjects in `Direct` group are now ~`10 %` less likely to respond, compared to `6%`(ignoring non-compliance).
  -  Subjects in `Philanthropic` group are now ~`4.4 %` less likely , compared to `6%` (ignoring non-compliance).
  
* The survey completion rate for the `Control` group is ~ `26%` on average (range = [`21.3%`,`31.3%`]), compared to the overall average of `21%.` These results are significant at a level of one percent.The 95% confidence interval, i.e the true survey response rate for this group could be anywhere between `26%` to `27%`.

* The `Direct` incentive group on the other hand is significant at `10%` level , hence the true response rate for this group could be anywhere between `5.4%` to `27.4%`.We can follow a similar approach to measure the `CACE` for the `Philanthropic` group. The coefficient is not statistically significant. The response rates for people in this group can vary from `10%` to `33.7%`.

Note - It is worth nothing that both the `Direct` and the `Philanthropic` groups are not significant at 5%.For the `Direct` group we observe significance at a `10%`level but the estimates for the `Philanthropic`group is not significant at all, given its large standard errors.


### Heterogeneous Treatment Effects (HTEs)

We also calculated to see whether the response rates were different by cohorts/gender. This could help us in determining a group that is most likely to respond in the event of a further intervention of a policy change.
Here, we analyze the results of how treatment effects vary by gender (*for compliers *).


```{r hte, echo = FALSE}

# HTE for different gender
m3 <- d[bounce == 0 & Gender != 'U' & complier == 1, lm(completion ~ Gender * Block)]
rse3 <- sqrt(diag(vcovHC(m3)))

# HTE for different gender, controlling for cohort effect
m4 <- d[bounce == 0 & Gender != 'U' & complier == 1, lm(completion ~ Gender * Block + factor(Year_Graduation))]
rse4<- sqrt(diag(vcovHC(m4)))
```


```{r hte_2 , echo= FALSE}

# HTE between grad year and treatment
m5 <- d[bounce == 0 & Gender != 'U' & complier == 1, lm(completion ~ factor(Year_Graduation) * Block)]
rse5 <- sqrt(diag(vcovHC(m5)))


m6 <- d[bounce == 0 & Gender != 'U' & complier == 1, lm(completion ~ factor(Year_Graduation) * Block + Gender)]
rse6 <- sqrt(diag(vcovHC(m6)))

```

The table below calculates the HTEs for Gender and Graduation-Year.

```{r stargazer gender , comment='', echo = FALSE}

stargazer(m3, m4,
          type="text",
          se = list(rse3, rse4),
          
          no.space = T,
          omit.stat = c('ser', 'f', 'adj.rsq'),
          omit = c('Year_Graduation'),
          add.lines = list(c('Cohort Fixed Effects?', 'No', 'Yes'),
                           c('Excl. Gender Unknown?', 'Yes', 'Yes')),

          title = "Heterogeneous Treatment Effect",
          covariate.labels = c('Male',
                               'Group: Direct', 'Group: Philanthropic',
                               'Male + Direct', 'Male + Philanthropic',
                               "Constant"),
          dep.var.labels = "Survey Completion")

```


We interpret one of these regression values with the help of a mathematical equation as below:
$$ Y = \beta_0 + \beta_1Block + \beta_2gender + \beta_3(Block*gender) + \epsilon$$

For *compliers* We interpret the regression results as follows(this is labeled as 'cohort Fixed Effects ? No ' in the table above):

* Response rates for females in `Control`group is highly significant and on average they respond at `38%`. Response rates might vary in the range of `24%` to `52%`.
* Response rates for *men* in `Control`group is **not** significant and on average they are likely to respond anywhere between `33%` to `66.2%`(range of confidence interval)
* The co-efficient of interaction term is **not** significant but we can calculate a range for the response rates.
- The response rates for females in the `Direct`group can rage from `16%` to `55%` , which is the confidence interval. In other words females in the `Direct` group are ~`3%` less likely to respond as compared to the females in the `control`group.But, it is extremely likely that this effect will arise by chance(insignificant p-value).
- The response rates for males in the `Direct`group can rage from `0%` to `46%` , which is the confidence interval. In other words males in the `Direct` group are ~`15%` less likely to respond as compared to the females in the `control`group.But, it is extremely likely that this effect will arise by chance(insignificant p-value).

With a similar analysis we can compare the response rates between males and females in the `Philanthropic` group.





We also performed a hetrogenous treatment analysis of gender and cohort groups. The chunk below calculates the model for HTEs across these groups.

```{r HTE by gender and cohort , echo=FALSE}
# HTE between grad year and treatment

m5 <- d[bounce == 0 & Gender != 'U' & complier == 1, lm(completion ~ factor(Year_Graduation) * Block)]
rse5 <- sqrt(diag(vcovHC(m5)))


m6 <- d[bounce == 0 & Gender != 'U' & complier == 1, lm(completion ~ factor(Year_Graduation) * Block + Gender)]
rse6 <- sqrt(diag(vcovHC(m6)))


```

In the code chunk below we evaluate whether any of the interaction models that we define are better at explaining the variance of the response rates. The `anova` analyzes this variance and evaluates the null hypothesis of a significant difference between variance of response rates between the two categories of interaction models that we have defined.


```{r hte_f_tests, echo=FALSE}

# F-test on gender
anova_gender<- anova(
  d[bounce == 0 & Gender != 'U' & complier == 1, lm(completion ~ Gender + Block)],
  d[bounce == 0 & Gender != 'U' & complier == 1, lm(completion ~ Gender * Block)],
  test = "F"
)

# F-test on graduation year
anova_gender_coh<- anova(
  m5 <- d[bounce == 0 & Gender != 'U' & complier == 1, lm(completion ~ factor(Year_Graduation) + Block)],
  m5 <- d[bounce == 0 & Gender != 'U' & complier == 1, lm(completion ~ factor(Year_Graduation) * Block)],
  test = "F"
)


```
Findings of `anova` test:
- The p-value of the difference between our base model(one that doesnt include interaction) and the interaction model of Gender is `r anova_gender$Pr[2]`, indicating that it is insignificant.
- The p-value of the difference between our non-interaction model(one that doesn't interact with year and block) and the interaction model(year and block interaction) is `r anova_gender_coh$Pr[2]`, indicating that it is insignificant as well.


Please refer to the appendix section for a table that describes the interaction effects of gender and cohort.

The table below represents the HTE values by cohort and gender. These values can be interpreted in a similar fashion as described above
.
```{r stargazer by gender and cohort}
stargazer(m5, m6,
          type="text",
          se = list(rse5, rse6),
          
          no.space = T,
          omit.stat = c('ser', 'f', 'adj.rsq'),
          omit = c('Gender'),
          add.lines = list(c('Gender Fixed Effects?', 'No', 'Yes'),
                           c('Excl. Gender Unknown?', 'Yes', 'Yes')),

          title = "Heterogeneous Treatment Effect",
          covariate.labels = c("Graduation: 2016", "Graduation: 2017",
                               "Graduation: 2018", "Graduation: 2019",
                               "Graduation: 2020", "Graduation: 2021",
                               "Group: Direct", "Group: Philanthropic",
                               "2016 + Direct", "2017 + Direct",
                               "2018 + Direct", "2019 + Direct",
                               "2020 + Direct", "2021 + Direct",
                               "2016 + Philanthropic", "2017 + Philanthropic",
                               "2018 + Philanthropic", "2019 + Philanthropic",
                               "2020 + Philanthropic", "2021 + Philanthropic",
                               "Constant"),
          dep.var.labels = "Survey Completion")


```

** A note on Generalizability:
We belive that our regression results are very specific for the MIDS population and cannot be generalized to any alumni. For a detailed discussion on generalizability, please refer to the `Conclusion` section.










