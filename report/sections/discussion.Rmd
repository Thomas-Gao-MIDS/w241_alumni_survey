# Discussion

In this section we'll discuss the following:
* Overall data aggregation
* Covariate balance check to validate randomization
* Calculation of the `treatment-effect`(ITT, HTE, CACE)

## Data flow and aggregation
As highlighted in the previous section ,our data comes from 3 main sources:

* Alumni Scrape - main data source that consists of alumni details that we obtain from web scraping.
* YAMM Mail Merge - Data from the mail-merge tool that helps to track the status of an email.We need this status to determine the `attriters,complies, non-compliers`.
* Qualtrics  - contains the information for subjects who take the survey.

We obtain our final dataset by performing a left-join of Alumni-Scrape  with YAMM and Qualtrics data. This helps us to assign each subject into oe of the categories - attriters, compliers, non-compliers.

The figure below represents the high-level data flow and aggregation of our data sources to arrive at our final data source for further analysis.Please refer to the previous section on the definition of each and refer to appendix C for the script.


```{r Data flow-diagram, echo=FALSE, fig.align = "center", out.width = "100%", fig.cap = "Data Flow"}
setwd('home/w241_alumni_survey')

knitr::include_graphics(here::here("report/images", "Data_flow.PNG"))
```
The script below contains the code to aggregate the data:

```{r load_data,echo=FALSE}
# list of people



dt_roster <- read_csv('../../data/alumni_scrape.csv', col_types=cols()) %>%
  select(Email = email, Gender = gender, Year_Graduation = year_graduation, 
         Block = blocking_genderyear_assignments) %>% 
  mutate(Block = ifelse(
    Block == 1, "Direct", ifelse(
      Block == 2, "Philanthropic", "Control")))

# attrition, bounced, round 1 post-send merged status
r1_g1_bounce <- read_csv('../../data/round1_0702_group1_0702_0941.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) %>%
  filter(MStatus == 'BOUNCED')
r1_g2_bounce <- read_csv('../../data/round1_0702_group2_0702_1028.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) %>%
  filter(MStatus == 'BOUNCED')
r1_g3_bounce <- read_csv('../../data/round1_0702_group3_0702_1055.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) %>%
  filter(MStatus == 'BOUNCED')

# final status, sent, opened
r1_g1_status <- read_csv('../../data/round1_0702_group1_0708_1033.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) 
r1_g2_status <- read_csv('../../data/round1_0702_group2_0708_1220.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) 
r1_g3_status <- read_csv('../../data/round1_0702_group3_0708_1122.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) 
r2_status <- read_csv('../../data/round2_0709_all_0716_1117.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) 
r3_status <- read_csv('../../data/round3_0716_all_0722_1046.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) 
r4_status <- read_csv('../../data/round4_0722_all_0723_1131.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) 
r5_status <- read_csv('../../data/round5_0723_all_0724_1219.csv', col_types=cols()) %>%
  select(Email, MStatus = `Merge status`) 

# outcome, Qualtrics completion
dt_qualtrics <- read_csv('../../data/Qualtrics_downloaded_20210726.csv', col_types=cols()) %>%
  select(Email = RecipientEmail, Duration = `Duration (in seconds)`,
         Long = LocationLongitude, Lat = LocationLatitude) %>%
  slice(3:n()) %>%
  mutate(Duration = as.numeric(Duration),
         Long = as.numeric(Long),
         Lat = as.numeric(Lat))

# emails to exclude
ex_emails <- c('deveshkhandelwal@berkeley.edu', 'rahosbach@berkeley.edu',
               'tgao2020@berkeley.edu', 'tgao2020@berkely.edu',
               'mirza2020@berkeley.edu')
```


```{r combine_data,echo= FALSE}

dt_agg <- 
  # roster does not contain us
  dt_roster %>%
  select(Email) %>%
  
  # bounce
  left_join(bind_rows(r1_g1_bounce, r1_g2_bounce, r1_g3_bounce) %>%
              add_column(bounce = 1) %>%
              select(-MStatus),
            by = 'Email') %>%
  replace(is.na(.), 0) %>%
  
  # non-compliance: email_sent status for all 5 rounds
  left_join(
    # EMAIL_SENT not balanced.
    #bind_rows(r1_g1_status %>% filter(MStatus == 'EMAIL_SENT'),
    #          r1_g2_status %>% filter(MStatus == 'EMAIL_SENT'),
    #          r1_g3_status %>% filter(MStatus == 'EMAIL_SENT')) %>%
    #  filter(!Email %in% ex_emails) %>%
    #inner_join(r2_status %>% filter(MStatus == 'EMAIL_SENT') %>% select(Email), 
    #           by='Email') %>%
    
    # EMAIL_SENT is balanced in r3, r4 and r5
    dt_roster %>% select(Email) %>% add_column(MStatus='EMAIL_SENT') %>%
      
      inner_join(r3_status %>% filter(MStatus == 'EMAIL_SENT') %>% select(Email), 
                 by='Email') %>%
      inner_join(r4_status %>% filter(MStatus == 'EMAIL_SENT') %>% select(Email), 
                 by='Email') %>% # 4 & 5 are the same?
      inner_join(r5_status %>% filter(MStatus == 'EMAIL_SENT') %>% select(Email), 
                 by='Email') %>%
      add_column(non_complier = 1) %>%
      select(-MStatus),
    by = 'Email') %>%
  replace(is.na(.), 0) %>%
  
  # compliers: people who opened at least 1 round
  mutate(complier = 1 - (bounce + non_complier)) %>%
  
  # completion: qualtrics records
  left_join(dt_qualtrics %>% select(Email) %>% add_column(completion=1), by = 'Email') %>%
  replace(is.na(.), 0) %>%
  
  # override some incorrect YAMM data
  # (these two lines correct rows for 4 people, all in the philanthropic group)
  # vishal, ansjory, taeil.goh, and davidhou
  mutate(non_complier = if_else(completion == 1, 0, non_complier),
         complier = if_else(completion == 1, 1, complier)) %>% 
  
  # meta data
  left_join(dt_roster, by = 'Email') %>%
  left_join(dt_qualtrics, by = 'Email') 

```




## Checks and balances 


Covariate balance checks is a recommended approach to validate randomization and a fair "apples to apples" comparison. While, one can perform a co-variaate balance check on different characteristics across the three groups, we focused on performing the balance check on the YAMM data to identify compliers,attriters and non-compliers. As we already pointed out and validated in the previous section that R blocking has already ensured that our data is balanced across cohorts and gender.
In Figure below, we plot the number of attriters, non-compliers and compilers, and through visual inspection, we see a similar attrition rate and compliance rate. 


```{r cov_balance , echo=FALSE}
dt_agg %>% 
  select(Block, bounce, non_complier, complier, completion) %>%
  gather(measure, value, -Block) %>%
  group_by(Block, measure) %>%
  summarise(value = sum(value)) %>%
  spread(measure, value) %>%
  select(Block, bounce, non_complier, complier, completion) %>%
  mutate(all = bounce + non_complier + complier, .before=2)



dt_cb <- dt_agg %>% 
  select(Block, bounce, non_complier, complier, completion)  %>%
  data.table()

cb1 <- dt_cb[, lm(bounce~Block)]
cb2 <- dt_cb[, lm(non_complier~Block)]
cb3 <- dt_cb[, lm(complier~Block)]



```

```{r Graphical Representation }
dt_agg %>% 
  select(Block, bounce, non_complier, complier, completion) %>%
  gather(measure, value, -Block) %>%
  group_by(Block, measure) %>%
  summarise(value = sum(value)) %>%
  ungroup() %>%
  filter(measure != 'completion') %>%
  mutate(measure = recode_factor(measure, 
                                 bounce = "Email Bounced (Attrition)", 
                                 non_complier = 'Did Not Open (Non-Complier)',
                                 complier = "Opened Email (Complier)")) %>%
  # plotting
  ggplot(aes(x=Block, y=value, fill=measure)) +
  geom_col() +
  labs(x='Treatment Group', y='Count', title='Covariate Balance Check',
       fill='Status') +
  scale_fill_brewer(palette = 'Accent') +
  theme_bw()

```
More formally, in the table below , we perform regression analysis of attrition, non-compliance and compliance status on the group assignment variable and did not find statistically different results of treatment groups from the control group.


```{r Co-variate Balance check stargazer , echo=FALSE}

stargazer(cb1, cb2, cb3, 
          type="text",
          
          omit.stat = c('ser', 'adj.rsq'),
          
          title = "Covariate Balance Check",
          covariate.labels = c("Group: Direct", 
                               "Group: Philanthropic",
                               "Constant"),
          dep.var.labels = c("Attrition", 'Non-Compliance', 'Compliance'))


```


## Non-Compliance

As with any survey we also ran into the issues of non-compliance. We believe that our survey is only impacted by *one-sided non-compliance* where people do not respond to assigned dosage of treatment(Direct, Philanthropic and Control). This is due to the fact that we generate personal links for alumni and refrained from using  generic survey link across groups.
Our mail-merge strategy(with personalized body and subject) gave an impression of a highly targeted campaign as opposed to a generic appeal to respond to a survey campaign.We assume that these approaches would *prevent any two-sided non-compliance* where people in separate groups share the survey link with one another.

As highlighted in the previous section we calculate the treatment effect in the following categories :
* Intent to Treat(ITT)
* Complier-Average Causal Effect (CACE)
* Heterogeneous Treatment Effects (HTEs)

### Calculation of ITT

The ultimate aim for a research is to determine the Average Treatment Effect (ATE) for a population,however due to practical challenges and given the issue of non-compliance it is not always possible to get an accurate measure of the ATE.Researchers often start with a measure of ITT -  effect of treatment on ASSIGNMENT on outcome (for everybody) ignoring non-compliance.

Mathematically we define ITT as:

$ ITT = E[Y_i(z = 1)] - E[Y_i(z = 0)]$

here, z denotes 'azzignment', to one of the experimental groups.

In our experiment we ran regressions to determine ITT by comparing the three groups and the response rates(ignoring the non-compliance).
The table below provides an overview of ITT along with ITT by factoring in the groups and cohort. In general, we observed that the response rates in the Direct and Philanthropic groups were low compared to the control group.


```{r ITT model, echo=FALSE, fig.align = "center", out.width = "100%", fig.cap = "ITT models"}
knitr::include_graphics(here::here("report/images", "ITT_stargazer.PNG"))
```

We also noticed that when controlled for `cohorts` and `gender` , our treatment effect marginally decreased (~1.2 % point decrease) for the control group along with an increase in corresponding standard errors. The width of confidence interval also increases thereby making it less precise.

### Calculation of CACE

Given the presence of `Non-compliers`(subjects who don't take the treatment dosage),a more realistic measure for the treatment effect would be to calculate the effect of the treatment on compliers(subjects who take at least one treatment dosage). It is this group of subjects who are most likely to respond to the treatment and hence reflects a better picture of the results.
Note - we assume that we don't have any `Defiers` in our data.

Mathematically,
$ ITT_D = E[d_i(z = 1)- d_i(z = 0)] $
$ CACE = E[Y_i(d = 1) -Y_i(d = 0)|d_i(1)=1] $

The `exclusion` restriction holds true for our experiment.This is because `attriters` have no possibility of receiving a treatment(their emails are no longer valid) and hence we can safely assume that assignment to the specific groups has no effect beyond the received treatment.Due to this we can simplify the CACE calculation as :

$ CACE = ITT/ ITT_D $


We calculated our case by first calculating the take-up rate(proportion of subjects in a group who respond to the survey) and then scaling the ITT values by the take-up rate.Please refer to figure \@ref(fig:flow-diagram) that shows the number of alumni in each group after accounting for attriters and non-compliers.

The table below provides a snapshot of CACE for the two treatment groups with the control group as the baseline.

```{r CACE, echo=FALSE, fig.align = "center", out.width = "100%", fig.cap = "CACE models"}
knitr::include_graphics(here::here("report/images", "CACE_Stargazer.PNG"))
```

We again observe that the response rates in the treatment groups were lower than the response rates in the control.However, there are a few subtle differences that should be noted(as a result of *one-sided non-compliance*). As compared to the `Control`group.
* Subjects in `Direct` group are now ~`10 %` less likely to respond, compared to `6%`(ignoring non-compliance).
* Subjects in `Philanthropic` group are now ~`4.4 %` less likely , compared to `6%` (ignoring non-compliance).

We believe that the results in the table above for CACE, measures the treatment better, compared to ITT. The survey completion rate for the `Control` group is ~ `26%`, compared to the overall average of `21%.` These results are significant at a level of one percent.The 95% confidence interval, i.e the true survey response rate for this group could be anywhere between `26%` to `27%`.

The `Direct` incentive group on the other hand is significant at `10%` level , hence the true response rate for this group could be anywhere between `0%` to `27.5%`.We can follow a similar approach to measure the `CACE` for the `Philanthropic` group. The coefficient is not statistically significant. The response rates for people in this group can vary from `10%` to `33.7%`.

Note - It is worth nothing that both the `Direct` and the `Philanthropic` groups are not significant at 5%.For the `Direct` group we observe significance at a `10%`level but the estimates for the `Philanthropic`group is not significant at all, given its large standard errors.


### Heterogeneous Treatment Effects (HTEs)

We were also interested to see whether the response rates were different by cohorts/gender. This could help us in determining a group that is most likely to respond in the event of a further intervention of a policy change.
Here, we analyze the results of how treatment effects vary by gender (*for compliers *).

```{r HTE by Gender, echo=FALSE, fig.align = "center", out.width = "100%", fig.cap = "HTE by Gender"}
knitr::include_graphics(here::here("report/images", "HTE_Gender_Stargazer.PNG"))
```
For a detailed results of HTEs by gender and cohorts, pls refer to the "Results" section.

The regression equation for the HTE above can be specified as :

$ Y = \beta_0 + \beta_1Block + \beta_2gender + \beta_3(Block*gender) + \epsilon$

For *compliers* We interpret the regression results as follows(this is labeled as 'cohort Fixed Effects ? No ' in the table above):
* Response rates for females in `Control`group is highly significant and on average they respond at `38%`
* Response rates for *men* in `Control`group is **not** significant and on average they are likely to respond anywhere between `38%` to `54.6%`(range of confidence interval)
* The co-efficient of interaction term is **not** significant but we can calculate a range for the response rates.
- The response rates for females in the `Direct`group can rage from `16%` to `58%` , which is the confidence interval. In other words females in the `Direct` group are ~`3%` less likely to respond as compared to the females in the `control`group.But, it is extremely likely that this effect will arise by chance(insignificant p-value).
- The response rates for males in the `Direct`group can rage from `0%` to `46%` , which is the confidence interval. In other words males in the `Direct` group are ~`15%` less likely to respond as compared to the females in the `control`group.But, it is extremely likely that this effect will arise by chance(insignificant p-value).

With a similar analysis we can compare the response rates between males and females in the `Philanthropic` group.













